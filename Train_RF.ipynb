{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IsvLeQds-zSj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "from multiprocessing import Pool\n",
        "import multiprocessing as mp\n",
        "import warnings\n",
        "import copy\n",
        "import math\n",
        "from pickle import dump"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pass the path of your final CSV file path to `MERGED_CSV_FILE_PATH` that has merged data from 2019, 2020, and 2021. We train one single model for all 3 years combined\n",
        "\n",
        "#### This notebook was run with a high CPU count machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d4pp57qg-2Vu"
      },
      "outputs": [],
      "source": [
        "MERGED_CSV_FILE_PATH = \"YOUR_MERGED_FOLDER_PATH/merged_2019_2020_2021.csv\"\n",
        "combined_dataframe = pd.read_csv(MERGED_CSV_FILE_PATH)\n",
        "combined_dataframe = combined_dataframe.drop(combined_dataframe.columns[0], axis=1)\n",
        "combined_dataframe['agbd_points'] = combined_dataframe['agbd_points'].apply(ast.literal_eval)\n",
        "combined_dataframe['overlap'] = combined_dataframe['overlap'].apply(ast.literal_eval)\n",
        "list_ = combined_dataframe.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eslJ4bsW-5HH"
      },
      "outputs": [],
      "source": [
        "dummies = pd.get_dummies(combined_dataframe.Ecoregion_l3)\n",
        "combined_dataframe_new = combined_dataframe.join(dummies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5cpVMya9-6Yn"
      },
      "outputs": [],
      "source": [
        "list_ = combined_dataframe_new.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UWRR-MsW-6t_"
      },
      "outputs": [],
      "source": [
        "def clean_up_list(l, overlap_percentage=0.5):\n",
        "  l = l.copy()\n",
        "  filtered_list = []\n",
        "  for i in l:\n",
        "    agbd = i[18]\n",
        "    overlap = i[23]\n",
        "    filtered_agbd = [value for value, b_value in zip(agbd, overlap) if b_value >= overlap_percentage]\n",
        "    i[18] = filtered_agbd.copy()\n",
        "  return l.copy()\n",
        "\n",
        "filterd_list = clean_up_list(copy.deepcopy(list_.copy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### We do training in two parts since having just one models leads to overpredicting or underpredicting values\n",
        "#### First fit an RF with training set\n",
        "#### Compute residuals = y_train - y_pred\n",
        "#### Fit an RF with these residuals as dependent variable against training set\n",
        "#### While predection first predict from RF model 1, then predict from RF model 2\n",
        "#### Add the results of both the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DRCSVpF_--DH"
      },
      "outputs": [],
      "source": [
        "def rf_bias_reg_IQ(X, y):\n",
        "  mae_list = []\n",
        "  rmse_list = []\n",
        "  mape_list = []\n",
        "  nrmse_list = []\n",
        "  r2_list = []\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=321)\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  model = RandomForestRegressor(n_estimators=500,\n",
        "                              min_samples_split=2,\n",
        "                              min_samples_leaf=1,\n",
        "                              max_features=10,\n",
        "                              max_depth=None,\n",
        "                              criterion=\"absolute_error\",\n",
        "                              random_state=42)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred_train = model.predict(X_train)\n",
        "\n",
        "  residuals = y_train - y_pred_train\n",
        "  model_bias = RandomForestRegressor(n_estimators=200,\n",
        "                                    min_samples_split=250,\n",
        "                                    min_samples_leaf=5,\n",
        "                                    max_features=10,\n",
        "                                    max_depth=10,\n",
        "                                    criterion=\"absolute_error\",\n",
        "                                     random_state=42)\n",
        "  model_bias.fit(X_train, residuals)\n",
        "\n",
        "  y_pred_test = model.predict(X_test)\n",
        "  estimated_residuals = model_bias.predict(X_test)\n",
        "  bias_corrected_predictions = y_pred_test + estimated_residuals\n",
        "  bias_corrected_predictions = np.exp(bias_corrected_predictions)\n",
        "\n",
        "  y_test = np.exp(y_test)\n",
        "\n",
        "  mse = mean_squared_error(y_test, bias_corrected_predictions)\n",
        "  mae = mean_absolute_error(y_test, bias_corrected_predictions)\n",
        "  r2_test = r2_score(y_test, bias_corrected_predictions)\n",
        "  mape = mean_absolute_percentage_error(y_test, bias_corrected_predictions) * 100.0\n",
        "  mae_list.append(mae)\n",
        "  rmse_list.append(mse**0.5)\n",
        "  r2_list.append(r2_test)\n",
        "  nrmse_list.append(((mse**0.5)/y_test.mean())*100.0)\n",
        "  mape_list.append(mape)\n",
        "\n",
        "  return mae_list, rmse_list, nrmse_list, mape_list, r2_list, \"rf_bias_reg_IQ\", [model, model_bias], [scaler]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Add the indices for the best features that was found from FeatureSelectionBulkOverlap.ipynb notebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BEST_FEATURES = [3, 9, 12, 14, 19, 21, 24]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QGC6pLlC---Y"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\", message=\"There are no meaningful features\")\n",
        "def do_analysis(mean_count):\n",
        "  print(\"Started Doing for mean count {}\\n\".format(mean_count))\n",
        "  filtered_by_region_mean = []\n",
        "  for index_, row in enumerate(filterd_list):\n",
        "    agbd_values = row[18]\n",
        "    if len(agbd_values) >= mean_count:\n",
        "      if all(value >= 0 for value in agbd_values):\n",
        "        \"\"\"3 = yeojohnson\n",
        "        9 = yeojohnson\n",
        "        12 = yeojohnson\n",
        "        14 = yeojohnson\n",
        "        19 = None\n",
        "        21 = yeojohnson\n",
        "        24 = yeojohnson\"\"\"\n",
        "        mean_agbd = sum(agbd_values) / len(agbd_values)\n",
        "        values_to_add = [row[i] for i in BEST_FEATURES + list(range(26, 44))]\n",
        "        values_to_add.append(math.log(mean_agbd))\n",
        "        filtered_by_region_mean.append(values_to_add)\n",
        "\n",
        "  data_array = np.array(filtered_by_region_mean)\n",
        "  X, y = data_array[:, :-1], data_array[:, -1]\n",
        "  transformer_dict = {idx: [PowerTransformer(method='yeo-johnson'), combined_dataframe_new.columns[original_idx]]  for original_idx, idx in zip([3, 9, 12, 14, 21, 24], [0, 1, 2, 3, 5, 6])}  # Map column indices to transformers\n",
        "  for idx in transformer_dict:\n",
        "      X[:, idx] = transformer_dict[idx][0].fit_transform(X[:, idx].reshape(-1, 1)).flatten()\n",
        "  Q1 = np.percentile(y, 25)\n",
        "  Q3 = np.percentile(y, 75)\n",
        "  IQR = Q3 - Q1\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "  y = np.where((y < lower_bound) | (y > upper_bound), np.nan, y)\n",
        "  X = X[~np.isnan(y)]\n",
        "  y = y[~np.isnan(y)]\n",
        "  results = []\n",
        "  args_ = (X, y)\n",
        "  results.append(rf_bias_reg_IQ(X, y))\n",
        "  for mae_c, rmse_c, mape_c, nrmse_c, r2, name_, model_, scaler_ in results:\n",
        "    rf_bias_reg_IQ_var = { \"mae\": mae_c, \"rmse\": rmse_c, \"mape\": mape_c,\n",
        "              \"nrmse\": nrmse_c, \"r2\": r2, \"model\": model_, \"scaler\": scaler_, \"Power_Transformer_states\": transformer_dict}\n",
        "\n",
        "  print(\"Finished Doing for mean count {}\\n\".format(mean_count))\n",
        "  return mean_count, rf_bias_reg_IQ_var"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Add the value for `BEST_MEAN_COUNT` that was found from Feature_SelectionBulk_Overlap.ipynb notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv7paMnX_AII",
        "outputId": "cf9762ed-23bb-4740-9521-645ec263651e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started Doing for mean count 14\n",
            "\n",
            "Finished Doing for mean count 14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "BEST_MEAN_COUNT = 14\n",
        "results = do_analysis(BEST_MEAN_COUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save the models for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7xhrqvONiW9S"
      },
      "outputs": [],
      "source": [
        "with open(\"RF_base_model.pkl\", \"wb\") as f:\n",
        "    dump(results[1]['model'][0], f, protocol=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K5pAWlkniW65"
      },
      "outputs": [],
      "source": [
        "with open(\"RF_bias_model.pkl\", \"wb\") as f:\n",
        "    dump(results[1]['model'][1], f, protocol=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Lc1Q4rJEiW4R"
      },
      "outputs": [],
      "source": [
        "with open(\"Standard_Scaler_Params.pkl\", \"wb\") as f:\n",
        "    dump(results[1]['model'][0], f, protocol=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in results[1]['Power_Transformer_states'].values():\n",
        "  with open(f\"Power_transform_params_{i[1]}.pkl\", \"wb\") as f:\n",
        "    dump(i[0], f, protocol=5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
