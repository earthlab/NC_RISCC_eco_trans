{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCup1H1TwkPZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "from pandas.errors import EmptyDataError\n",
        "from multiprocessing import Pool\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMEDWhQ9lgdE"
      },
      "outputs": [],
      "source": [
        "def read_csv(csv_list):\n",
        "  # Attempt to read the provided list of CSV files into DataFrames\n",
        "  try:\n",
        "    dataframes = []  # Initialize an empty list to store DataFrames\n",
        "    for file_ in csv_list:\n",
        "      if not file_.endswith('.csv'):  # Skip non-CSV files\n",
        "          continue\n",
        "      df = pd.read_csv(file_)  # Read the CSV file into a DataFrame\n",
        "      dataframes.append(df)  # Add the DataFrame to the list\n",
        "    print(\"Finished doing batch\")  # Log message to indicate batch processing completion\n",
        "    return dataframes  # Return the list of DataFrames\n",
        "  except EmptyDataError:\n",
        "    # If an EmptyDataError occurs (due to an empty CSV file), return an empty list\n",
        "    return []\n",
        "\n",
        "def merge_csv(all_csv, processes = 4):\n",
        "  # Function to split the CSV files into batches and merge them in parallel using multiple processes\n",
        "  batch_size = len(all_csv) // processes  # Determine the size of each batch based on the number of processes\n",
        "  all_batches = []  # Initialize a list to store the batches\n",
        "  dataframes = []  # Initialize an empty list to hold DataFrames from batches\n",
        "  count = 0  # Initialize a counter (unused, but could be useful for tracking)\n",
        "\n",
        "  # Split the list of all CSV files into batches\n",
        "  for i in range(0, len(all_csv), batch_size):\n",
        "    batch_files = all_csv[i:i + batch_size]  # Get a batch of files\n",
        "    all_batches.append(batch_files)  # Append the batch to the list\n",
        "\n",
        "  # Use a multiprocessing Pool to read and process batches in parallel\n",
        "  with Pool(processes=processes) as pool:\n",
        "    dataframes = pool.map(read_csv, all_batches)  # Map the read_csv function to each batch\n",
        "\n",
        "  # Merge the DataFrames from all batches\n",
        "  merged_gdf = merge_dataframe(dataframes)\n",
        "\n",
        "  # Return the merged GeoDataFrame (or DataFrame)\n",
        "  return merged_gdf\n",
        "\n",
        "def merge_dataframe(dataframes):\n",
        "  # Function to merge all DataFrames into a single DataFrame\n",
        "  merged_gdf = None  # Initialize the final merged DataFrame as None\n",
        "  for frame in dataframes:\n",
        "    if len(frame) == 0:  # Skip empty DataFrames\n",
        "      continue\n",
        "    # Concatenate the DataFrames in the current batch, ignoring index for a continuous DataFrame\n",
        "    batch_gdf = pd.concat(frame, ignore_index=True)\n",
        "\n",
        "    if merged_gdf is None:\n",
        "      # If this is the first batch, initialize merged_gdf with the current batch\n",
        "      merged_gdf = batch_gdf\n",
        "    else:\n",
        "      # Otherwise, concatenate the current batch with the existing merged_gdf\n",
        "      merged_gdf = pd.concat([merged_gdf, batch_gdf], ignore_index=True)\n",
        "\n",
        "  # Return the fully merged DataFrame\n",
        "  return merged_gdf\n",
        "\n",
        "def get_csv_list(folder_path):\n",
        "  # Function to retrieve a sorted list of CSV files from the specified folder\n",
        "  csv_list = []  # Initialize an empty list to store CSV file paths\n",
        "\n",
        "  # Iterate through all files in the directory\n",
        "  for i in os.listdir(folder_path):\n",
        "    if i.endswith(\".csv\"):  # If the file ends with '.csv', add it to the list\n",
        "      csv_list.append(i)\n",
        "\n",
        "  # Sort the CSV list based on the integer value in the file name (assumed to be at index 2 when split by '_')\n",
        "  csv_list = sorted(csv_list, key=lambda x: int(x.split(\"_\")[2]))\n",
        "\n",
        "  # Update the list with full file paths by joining folder path and file name\n",
        "  csv_list = [os.path.join(folder_path, i) for i in csv_list]\n",
        "\n",
        "  # Return the final list of sorted CSV file paths\n",
        "  return csv_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXR6WaUZ3IZ_"
      },
      "outputs": [],
      "source": [
        "l3_regs = ['15  Northern Rockies',\n",
        "       '16  Idaho Batholith', '17  Middle Rockies', '18  Wyoming Basin',\n",
        "       '19  Wasatch and Uinta Mountains', '20  Colorado Plateaus',\n",
        "       '21  Southern Rockies', '22  Arizona/New Mexico Plateau',\n",
        "       '25  High Plains', '26  Southwestern Tablelands',\n",
        "       '27  Central Great Plains', '41  Canadian Rockies',\n",
        "       '42  Northwestern Glaciated Plains', '43  Northwestern Great Plains',\n",
        "       '44  Nebraska Sand Hills', '46  Northern Glaciated Plains',\n",
        "       '47  Western Corn Belt Plains', '48  Lake Agassiz Plain']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MnDFf9o3O1c"
      },
      "source": [
        "#### Add the names for the best features that was found from FeatureSelectionBulkOverlap.ipynb notebook. Make sure the variable follows the same order as the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWc3HVTD3Odr"
      },
      "outputs": [],
      "source": [
        "BEST_FEATURES_BY_NAME = [\"EVI_mean\", \"Fpar_mean_annual\", \"NDVI_mean\", \"NDWI_mean\", \"aspect\", \"elevation\", \"slope\"]\n",
        "BEST_TRANSFORMATION_FOR_FEATURES = [\"yeojohnson\", \"yeojohnson\", \"yeojohnson\", \"yeojohnson\", None, \"yeojohnson\", \"yeojohnson\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XE9NxlUjwt1J"
      },
      "outputs": [],
      "source": [
        "def get_list_and_predict():\n",
        "    list_ = dataframes.values.tolist()\n",
        "    X_test = []\n",
        "    X_geo = []\n",
        "\n",
        "    # Prepare the test data with the specified columns and ecoregion encoding\n",
        "    for row in list_:\n",
        "        values_to_add = [row[i] for i in [3, 6, 9, 11, 15, 17, 18]]  # Using the BEST_FEATURES_BY_NAME indices\n",
        "        l3_vals = [0 for i in range(18)]  # add the eco regions\n",
        "        if row[16] in l3_regs:\n",
        "            l3_vals[l3_regs.index(row[16])] = 1\n",
        "        values_to_add.extend(l3_vals)\n",
        "        X_test.append(values_to_add)\n",
        "        X_geo.append(row[-1])\n",
        "\n",
        "    X_test = np.array(X_test)\n",
        "\n",
        "    # Apply the appropriate transformation for each feature\n",
        "    for idx, (feature_name, transformation) in enumerate(zip(BEST_FEATURES_BY_NAME, BEST_TRANSFORMATION_FOR_FEATURES)):\n",
        "        if transformation is not None:\n",
        "            power_transform_filename = f\"Power_transform_params_{feature_name}.pkl\"\n",
        "            with open(power_transform_filename, 'rb') as f:\n",
        "                power_transformer = pickle.load(f)\n",
        "\n",
        "            # Apply the power transform to the feature\n",
        "            X_test[:, idx] = power_transformer.transform(X_test[:, idx].reshape(-1, 1)).flatten()\n",
        "        else:\n",
        "            # If no transformation, just keep the original values\n",
        "            X_test[:, idx] = X_test[:, idx]  # No operation needed, but placeholder\n",
        "\n",
        "    # Load the model, bias model, and scaler\n",
        "    with open(\"RF_base_model.pkl\", 'rb') as f:\n",
        "        rf_base_model = pickle.load(f)\n",
        "    with open(\"RF_bias_model.pkl\", 'rb') as f:\n",
        "        rf_bias_model = pickle.load(f)\n",
        "    with open(\"Standard_Scaler_Params.pkl\", 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "\n",
        "    # Scale the transformed data\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Perform predictions\n",
        "    X_pred = rf_base_model.predict(X_test)\n",
        "    residual_predict = rf_bias_model.predict(X_test)\n",
        "\n",
        "    # Calculate final predictions\n",
        "    new_pred = np.exp(X_pred + residual_predict)\n",
        "\n",
        "    # Create a new dataframe with predictions\n",
        "    new_df = copy.deepcopy(dataframes.copy())\n",
        "    new_df.insert(2, 'agbd_prediction', new_pred)\n",
        "\n",
        "    return new_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Change the name of states you want to predict {KS, NE, CO, MT, ND, SD, WY}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JHkt8ZZbDmQf"
      },
      "outputs": [],
      "source": [
        "stateName = \"WY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU3EtMcXw1rI",
        "outputId": "6b2e8bd3-504b-42a8-d10c-a4707ecc1e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2007\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2015\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2003\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2004\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2005\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2006\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2008\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "\n",
            "Predicting for /content/drive/MyDrive/WY/EarthLabWY_year_2009\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batchFinished doing batch\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batchFinished doing batchFinished doing batch\n",
            "Finished doing batch\n",
            "\n",
            "\n",
            "Finished doing batch\n",
            "Finished doing batch\n"
          ]
        }
      ],
      "source": [
        "# the data we predict \"on\" is pre-downloaded\n",
        "# the data is stored in /data/{StateName}\n",
        "# the data is structured like\n",
        "#   data\n",
        "#     StateName\n",
        "#       YearWise Folders\n",
        "#         All csv files\n",
        "\n",
        "# after running prediction, we will store the data at /data/predictions/{StateName}\n",
        "\n",
        "baseDataFolderName = \"data\"\n",
        "dataFolderName = os.path.join(baseDataFolderName, stateName)\n",
        "folderToSavePreds = os.path.join(baseDataFolderName, \"predictions\", stateName)\n",
        "os.makedirs(folderToSavePreds, exist_ok=True)\n",
        "if __name__ == \"__main__\":\n",
        "  for folderToPredict_ in os.listdir(dataFolderName):\n",
        "    folderToPredict = os.path.join(dataFolderName, folderToPredict_)\n",
        "    print(f\"Predicting for {folderToPredict}\")\n",
        "    csv_year = get_csv_list(folderToPredict)\n",
        "    dataframes = merge_csv(csv_year, processes=32)\n",
        "    predicted_dataframes = get_list_and_predict()\n",
        "    predicted_dataframes.to_csv(os.path.join(folderToSavePreds, f\"{folderToPredict_}.csv\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
